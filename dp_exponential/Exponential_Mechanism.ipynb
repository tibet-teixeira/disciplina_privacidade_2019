{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import rv_discrete\n",
    "from collections import Counter\n",
    "import operator\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "COLUMN NAME - INDEX\n",
    "gross           8\n",
    "movie_title    11\n",
    "language       19\n",
    "country        20\n",
    "'''\n",
    "def loadDataset(filename):\n",
    "    dataset = pd.read_csv(filename, delimiter=',')\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearingDatasetQuery1(dataset):\n",
    "    subset = dataset[:, [8, 11]]\n",
    "    new_dataset = list()\n",
    "    for record in subset:\n",
    "        if not(math.isnan(record[0])):\n",
    "            new_dataset.append(record)\n",
    "    return np.array(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove line limite  \n",
    "def clearingDatasetQuery2(dataset):   \n",
    "    subset = dataset[:, [8, 11, 19]]\n",
    "    new_dataset = list()\n",
    "    for record in subset:\n",
    "        if not(math.isnan(record[0])):\n",
    "            new_dataset.append(record)\n",
    "    return np.array(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearingDatasetQuery3(dataset):   \n",
    "    subset = dataset[:, [20, 11]]\n",
    "    df = pd.DataFrame({'country':subset[:,0], 'title':subset[:,1]})\n",
    "    new_dataset = np.array(df.dropna())\n",
    "    \n",
    "    countOccurrences = Counter(new_dataset[:,0]) \n",
    "\n",
    "    newDataset = list()\n",
    "    languages = list()\n",
    "    counts = list()\n",
    "    \n",
    "    for language in countOccurrences:\n",
    "        languages.append(language)\n",
    "        counts.append(countOccurrences[language])\n",
    "    newDataset = np.array(pd.DataFrame({'language':languages, 'count':counts}))\n",
    "    \n",
    "    return newDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possibleValues(dataset, query):  \n",
    "    if query == 1:\n",
    "        cleanDataset = clearingDatasetQuery1(dataset)\n",
    "    elif query == 2:\n",
    "        cleanDataset = clearingDatasetQuery2(dataset)\n",
    "    else:\n",
    "        print('Consulta invÃ¡lida')\n",
    "        return None\n",
    "       \n",
    "    indexRecord = 0\n",
    "    titleUniqueMovies = list()\n",
    "    removingReplicates = np.copy(cleanDataset)\n",
    "    \n",
    "    for record in cleanDataset:\n",
    "        if record[1] not in titleUniqueMovies:\n",
    "            titleUniqueMovies.append(record[1])\n",
    "        else:\n",
    "            removingReplicates = np.delete(removingReplicates, indexRecord, 0)\n",
    "            indexRecord -= 1\n",
    "            \n",
    "        indexRecord += 1\n",
    "       \n",
    "    return np.array(removingReplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(dataset):\n",
    "    movieDict = dict()\n",
    "    maxGrossPerLanguage = dict()\n",
    "    \n",
    "    for record in dataset:\n",
    "        if record[2] in movieDict.keys():\n",
    "            movieDict[record[2]].append(record)\n",
    "        else:\n",
    "            movieDict[record[2]] = []\n",
    "            movieDict[record[2]].append(record)\n",
    "    return movieDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query1(dataset):\n",
    "    maxGross = np.max(dataset[:, 0], axis=0)\n",
    "    return dataset[np.where(dataset[:,0] == maxGross)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query2(dataset):\n",
    "    movieDict = dict()\n",
    "    maxGrossPerLanguage = dict()\n",
    "    \n",
    "    for record in dataset:\n",
    "        if record[2] in movieDict.keys():\n",
    "            movieDict[record[2]].append(record)\n",
    "        else:\n",
    "            movieDict[record[2]] = []\n",
    "            movieDict[record[2]].append(record)\n",
    "        \n",
    "    for key in movieDict.keys():\n",
    "        maxGross = float('-inf')\n",
    "        movieName = None\n",
    "        for value in movieDict[key]:\n",
    "            if value[0] > maxGross:\n",
    "                maxGross = value[0]\n",
    "                movieName = value[1]\n",
    "\n",
    "        maxGrossPerLanguage[key] = (maxGross, movieName)\n",
    "\n",
    "    return maxGrossPerLanguage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query3(dataset):  \n",
    "    return sorted(dataset, key=lambda row: row[1], reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreFunctionQuery1(dataset, output):\n",
    "    \n",
    "    score = list()\n",
    "       \n",
    "    for record in dataset:       \n",
    "        if record[1] == output:\n",
    "            score.append(record[0])\n",
    "        else:\n",
    "            score.append(0)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreFunctionQuery2(dataset, output):\n",
    "    score = list()\n",
    "       \n",
    "    for record in dataset:       \n",
    "        if record[1] == output:\n",
    "            score.append(record[0])\n",
    "        else:\n",
    "            score.append(0)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreFunctionQuery3(dataset, output):\n",
    "    score = list()\n",
    "       \n",
    "    for record in dataset:       \n",
    "        if record[0] == output:\n",
    "            score.append(record[1])\n",
    "        else:\n",
    "            score.append(0)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivityQuery1(dataset):\n",
    "    return np.max(dataset[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivityQuery2(dataset):\n",
    "    datasetPerLanguage = splitDataset(dataset)\n",
    "    maxScorePerLanguage = dict()\n",
    "    \n",
    "    for language in datasetPerLanguage.keys():\n",
    "        maxScorePerLanguage[language] = np.max(np.array(datasetPerLanguage[language])[:,0])\n",
    "\n",
    "    return maxScorePerLanguage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivityQuery3(dataset):\n",
    "    return np.max(dataset[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateExp(score, budget, sensitivity):\n",
    "    return math.exp((budget * score) / (2 * sensitivity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateOutputProbabilityQuery1(dataset, budget, sensitivity):\n",
    "    expList = list()\n",
    "    probabilityList = list()\n",
    "    \n",
    "    for output in dataset:\n",
    "        score = np.max(scoreFunctionQuery1(dataset, output[1]))\n",
    "        expList.append(calculateExp(score, budget, sensitivity))\n",
    "        \n",
    "    sumExp = np.sum(expList)\n",
    "    \n",
    "    for value in expList:\n",
    "        probabilityList.append(value/sumExp)\n",
    "        \n",
    "    return probabilityList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateOutputProbabilityQuery2(dataset, language, budget, sensitivity):\n",
    "    expList = list()\n",
    "    probabilityList = list()\n",
    "    \n",
    "    for output in dataset:        \n",
    "        score = np.max(scoreFunctionQuery2(dataset, output[1]))\n",
    "        expList.append(calculateExp(score, budget, sensitivity[language]))\n",
    "\n",
    "    sumExp = np.sum(expList)\n",
    "    \n",
    "    for value in expList:\n",
    "        probabilityList.append(value/sumExp)\n",
    "        \n",
    "    return probabilityList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateOutputProbabilityQuery3(dataset, budget, sensitivity):\n",
    "    expList = list()\n",
    "    probabilityList = list()\n",
    "    \n",
    "    for output in dataset:\n",
    "        score = np.max(scoreFunctionQuery3(dataset, output[0]))\n",
    "        expList.append(calculateExp(score, budget, sensitivity))\n",
    "        \n",
    "    sumExp = np.sum(expList)\n",
    "    \n",
    "    for value in expList:\n",
    "        probabilityList.append(value/sumExp)\n",
    "        \n",
    "    return probabilityList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomizedQuery1(dataset, budget, sensitivity):\n",
    "    lenDataset = len(dataset)\n",
    "    listProbabilities = calculateOutputProbabilityQuery1(dataset, budget, sensitivity)\n",
    "    distribution = rv_discrete(values = (np.array(range(lenDataset)) , listProbabilities))\n",
    "    return dataset[distribution.rvs(size=1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomizedQuery2(dataset, budget, sensitivity):\n",
    "    datasetPerLanguage = splitDataset(dataset)\n",
    "    grossPerLanguage = dict()\n",
    "    \n",
    "    for language in datasetPerLanguage.keys():\n",
    "        newDataset = list()\n",
    "        \n",
    "        for record in datasetPerLanguage[language]:\n",
    "            newDataset.append(record)\n",
    "        \n",
    "        newDataset = np.array(newDataset)\n",
    "        \n",
    "        lenDataset = len(newDataset)\n",
    "        listProbabilities = calculateOutputProbabilityQuery2(newDataset, language, budget, sensitivity)\n",
    "        distribution = rv_discrete(values = (np.array(range(lenDataset)) , listProbabilities))\n",
    "        grossPerLanguage[language] = newDataset[distribution.rvs(size=1), :]\n",
    "        \n",
    "    return grossPerLanguage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomizedQuery3(dataset, budget, sensitivity):\n",
    "    budget = budget/3\n",
    "    \n",
    "    rankedList = list()\n",
    "    lenDataset = len(dataset)\n",
    "    \n",
    "    for rank in range(3):        \n",
    "        listProbabilities = calculateOutputProbabilityQuery3(dataset, budget, sensitivity)\n",
    "        distribution = rv_discrete(values = (np.array(range(lenDataset)) , listProbabilities))\n",
    "        indexOutput = distribution.rvs(size=1)\n",
    "        rankedList.append(dataset[indexOutput, :])\n",
    "                \n",
    "        dataset = dataset[np.delete(np.array(range(lenDataset)), indexOutput),:]\n",
    "        lenDataset = len(dataset)\n",
    "        \n",
    "    return rankedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "listabudget = []\n",
    "listaR1 = []\n",
    "listaR2 = []\n",
    "listaR3 = []\n",
    "listaS1 = []\n",
    "listaS2 = []\n",
    "listaS3 = []\n",
    "\n",
    "\n",
    "def main(filename, budgets):\n",
    "#     with open('result.csv', 'w') as f:\n",
    "    resultado = open(\"result.csv\",'w')\n",
    "    \n",
    "    dataset = loadDataset(filename)\n",
    "\n",
    "    datasetQuery1 = possibleValues(dataset, 1)\n",
    "    datasetQuery2 = possibleValues(dataset, 2)\n",
    "    datasetQuery3 = clearingDatasetQuery3(dataset)\n",
    "\n",
    "    q1 = query1(datasetQuery1)\n",
    "    q2 = query2(datasetQuery2)\n",
    "    q3 = query3(datasetQuery3)\n",
    "\n",
    "    sensQ1 = sensitivityQuery1(datasetQuery1)\n",
    "    sensQ2 = sensitivityQuery2(datasetQuery2)\n",
    "    sensQ3 = sensitivityQuery3(datasetQuery3)\n",
    "\n",
    "    for budget in budgets:\n",
    "\n",
    "        randomized1 = randomizedQuery1(datasetQuery1, budget, sensQ1)\n",
    "        randomized2 = randomizedQuery2(datasetQuery2, budget, sensQ2)\n",
    "        randomized3 = randomizedQuery3(datasetQuery3, budget, sensQ3)\n",
    "\n",
    "        print('Budget {} \\n'.format(budget))\n",
    "\n",
    "        print('Original query 1 = {} '.format(q1[0]))\n",
    "        print('Randomized query 1 = {} '.format(randomized1[0][1]))\n",
    "        print('Sensitivity query 1 = {} '.format(sensQ1))\n",
    "        print('\\n')\n",
    "\n",
    "        print('Original query 2 = {} '.format(q2))\n",
    "        print('Randomized query 2 = {} '.format(randomized2))\n",
    "        print('Sensitivity query 2 = {} '.format(sensQ2))\n",
    "        print('\\n')\n",
    "\n",
    "        print('Original query 3 = {} '.format(q3))\n",
    "        print('Randomized query 3 = {} '.format(randomized3))\n",
    "        print('Sensitivity query 3 = {} '.format(sensQ3))\n",
    "        print('\\n')\n",
    "\n",
    "        resp2String = \"\"\n",
    "        for i in randomized2.keys():\n",
    "            resp2String += str( randomized2[i] ) + \",\"\n",
    "            \n",
    "        resp3String = \"\"\n",
    "        print(randomized3)\n",
    "        for i in randomized3:\n",
    "            resp3String += str(i[0]) + \",\"\n",
    "            \n",
    "#         listabudget.append(budget)\n",
    "#         listaR1.append(randomized1)\n",
    "#         listaR2.append(resp2)\n",
    "#         listaR3.append(resp3)\n",
    "#         listaS1.append(sensQ1)\n",
    "#         listaS2.append(sensQ2)\n",
    "#         listaS3.append(sensQ3)\n",
    "    \n",
    "#     dicionario = {}\n",
    "#     dicionario[\"budget\"] = listabudget\n",
    "#     dicionario[\"r1\"] = listaR1\n",
    "#     dicionario[\"r2\"] = listaR2\n",
    "#     dicionario[\"r3\"] = listaR3\n",
    "#     dicionario[\"s1\"] = listaS1\n",
    "#     dicionario[\"s2\"] = listaS2\n",
    "#     dicionario[\"s3\"] = listaS3\n",
    "    \n",
    "#     resultado = pd.DataFrame.from_dict( dicionario )\n",
    "#     resultado.to_csv(\"resultado.csv\")\n",
    "#             f.write(\"{},\\t{},\\t{},\\t{}\\t{}\\t{}\\t{}\\n\".format(budget,randomized1,resp2,randomized3,sensQ1,sensQ2,sensQ3))\n",
    "\n",
    "        resultado.write(\"{};{};{};{};{};{};{}\\n\".format(budget,randomized1,resp2String,resp3String,sensQ1,sensQ2,sensQ3))\n",
    "    resultado.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget 0.1 \n",
      "\n",
      "Original query 1 = 760505847.0 \n",
      "Randomized query 1 = The MusketeerÂ  \n",
      "Sensitivity query 1 = 760505847.0 \n",
      "\n",
      "\n",
      "Original query 2 = {'English': (760505847.0, 'Avatar\\xa0'), 'Mandarin': (128067808.0, 'Crouching Tiger, Hidden Dragon\\xa0'), 'Aboriginal': (72515360.0, 'The Interpreter\\xa0'), 'Spanish': (45356386.0, 'The Legend of Zorro\\xa0'), 'French': (77413017.0, 'March of the Penguins\\xa0'), 'Filipino': (10166502.0, 'The Great Raid\\xa0'), 'Hindi': (13876974.0, 'Monsoon Wedding\\xa0'), 'Maya': (50859889.0, 'Apocalypto\\xa0'), 'Kazakh': (77231.0, 'Nomad: The Warrior\\xa0'), 'Telugu': (6498000.0, 'Baahubali: The Beginning\\xa0'), 'Cantonese': (32333860.0, 'Rumble in the Bronx\\xa0'), 'Japanese': (15081783.0, 'Ponyo\\xa0'), 'Aramaic': (499263.0, 'The Passion of the Christ\\xa0'), 'Italian': (15091542.0, 'The Adventures of Pinocchio\\xa0'), 'Dutch': (4398392.0, 'Black Book\\xa0'), 'Dari': (15797907.0, 'The Kite Runner\\xa0'), 'German': (11433134.0, 'Das Boot\\xa0'), 'Hebrew': (2408553.0, 'The Gatekeepers\\xa0'), 'Mongolian': (5701643.0, 'Mongol: The Rise of Genghis Khan\\xa0'), 'Russian': (1487477.0, 'Night Watch\\xa0'), 'Thai': (11905519.0, 'The Protector\\xa0'), 'Polish': (3826455.0, 'Ida\\xa0'), 'Bosnian': (301305.0, 'In the Land of Blood and Honey\\xa0'), 'Korean': (2181290.0, 'Oldboy\\xa0'), 'Hungarian': (195888.0, 'Fateless\\xa0'), 'Portuguese': (7563397.0, 'City of God\\xa0'), nan: (3000000.0, 'Over the Hill to the Poorhouse\\xa0'), 'Icelandic': (11835.0, 'Of Horses and Men\\xa0'), 'Danish': (1647780.0, 'The Celebration\\xa0'), 'Chinese': (50000.0, 'My Lucky Star\\xa0'), 'Norwegian': (1196752.0, 'Headhunters\\xa0'), 'Czech': (617228.0, 'I Served the King of England\\xa0'), 'Swedish': (188870.0, 'Easy Money\\xa0'), 'None': (2601847.0, 'Samsara\\xa0'), 'Zulu': (2912363.0, 'Tsotsi\\xa0'), 'Dzongkha': (505295.0, 'Travelers and Magicians\\xa0'), 'Arabic': (1060591.0, 'Caramel\\xa0'), 'Vietnamese': (638951.0, 'Journey from the Fall\\xa0'), 'Indonesian': (4105123.0, 'The Raid: Redemption\\xa0'), 'Romanian': (1185783.0, '4 Months, 3 Weeks and 2 Days\\xa0'), 'Persian': (7098492.0, 'A Separation\\xa0'), 'Greek': (110197.0, 'Dogtooth\\xa0')} \n",
      "Randomized query 2 = {'English': array([[95720716.0, 'Zero Dark Thirty\\xa0', 'English']], dtype=object), 'Mandarin': array([[6594136.0, 'The Grandmaster\\xa0', 'Mandarin']], dtype=object), 'Aboriginal': array([[6165429.0, 'Rabbit-Proof Fence\\xa0', 'Aboriginal']], dtype=object), 'Spanish': array([[5895238.0, 'Casa de mi Padre\\xa0', 'Spanish']], dtype=object), 'French': array([[1050445.0, 'Joyeux Noel\\xa0', 'French']], dtype=object), 'Filipino': array([[10166502.0, 'The Great Raid\\xa0', 'Filipino']], dtype=object), 'Hindi': array([[563699.0, 'Dum Maaro Dum\\xa0', 'Hindi']], dtype=object), 'Maya': array([[50859889.0, 'Apocalypto\\xa0', 'Maya']], dtype=object), 'Kazakh': array([[77231.0, 'Nomad: The Warrior\\xa0', 'Kazakh']], dtype=object), 'Telugu': array([[6498000.0, 'Baahubali: The Beginning\\xa0', 'Telugu']],\n",
      "      dtype=object), 'Cantonese': array([[261481.0, '2046\\xa0', 'Cantonese']], dtype=object), 'Japanese': array([[15081783.0, 'Ponyo\\xa0', 'Japanese']], dtype=object), 'Aramaic': array([[499263.0, 'The Passion of the Christ\\xa0', 'Aramaic']],\n",
      "      dtype=object), 'Italian': array([[3500000.0, 'A Fistful of Dollars\\xa0', 'Italian']], dtype=object), 'Dutch': array([[542860.0, 'Winter in Wartime\\xa0', 'Dutch']], dtype=object), 'Dari': array([[1127331.0, 'Osama\\xa0', 'Dari']], dtype=object), 'German': array([[95016.0, 'Summer Storm\\xa0', 'German']], dtype=object), 'Hebrew': array([[2283276.0, 'Waltz with Bashir\\xa0', 'Hebrew']], dtype=object), 'Mongolian': array([[5701643.0, 'Mongol: The Rise of Genghis Khan\\xa0', 'Mongolian']],\n",
      "      dtype=object), 'Russian': array([[1487477.0, 'Night Watch\\xa0', 'Russian']], dtype=object), 'Thai': array([[11905519.0, 'The Protector\\xa0', 'Thai']], dtype=object), 'Polish': array([[447093.0, 'Dekalog\\xa0            ', 'Polish']], dtype=object), 'Bosnian': array([[301305.0, 'In the Land of Blood and Honey\\xa0', 'Bosnian']],\n",
      "      dtype=object), 'Korean': array([[2181290.0, 'Oldboy\\xa0', 'Korean']], dtype=object), 'Hungarian': array([[195888.0, 'Fateless\\xa0', 'Hungarian']], dtype=object), 'Portuguese': array([[20262.0, 'Futuro Beach\\xa0', 'Portuguese']], dtype=object), nan: array([[252726.0, \"Love's Abiding Joy\\xa0\", nan]], dtype=object), 'Icelandic': array([[11835.0, 'Of Horses and Men\\xa0', 'Icelandic']], dtype=object), 'Danish': array([[610968.0, 'The Hunt\\xa0', 'Danish']], dtype=object), 'Chinese': array([[50000.0, 'My Lucky Star\\xa0', 'Chinese']], dtype=object), 'Norwegian': array([[1196752.0, 'Headhunters\\xa0', 'Norwegian']], dtype=object), 'Czech': array([[617228.0, 'I Served the King of England\\xa0', 'Czech']],\n",
      "      dtype=object), 'Swedish': array([[188870.0, 'Easy Money\\xa0', 'Swedish']], dtype=object), 'None': array([[2601847.0, 'Samsara\\xa0', 'None']], dtype=object), 'Zulu': array([[2912363.0, 'Tsotsi\\xa0', 'Zulu']], dtype=object), 'Dzongkha': array([[505295.0, 'Travelers and Magicians\\xa0', 'Dzongkha']],\n",
      "      dtype=object), 'Arabic': array([[1060591.0, 'Caramel\\xa0', 'Arabic']], dtype=object), 'Vietnamese': array([[638951.0, 'Journey from the Fall\\xa0', 'Vietnamese']],\n",
      "      dtype=object), 'Indonesian': array([[4105123.0, 'The Raid: Redemption\\xa0', 'Indonesian']],\n",
      "      dtype=object), 'Romanian': array([[1185783.0, '4 Months, 3 Weeks and 2 Days\\xa0', 'Romanian']],\n",
      "      dtype=object), 'Persian': array([[7098492.0, 'A Separation\\xa0', 'Persian']], dtype=object), 'Greek': array([[110197.0, 'Dogtooth\\xa0', 'Greek']], dtype=object)} \n",
      "Sensitivity query 2 = {'English': 760505847.0, 'Mandarin': 128067808.0, 'Aboriginal': 72515360.0, 'Spanish': 45356386.0, 'French': 77413017.0, 'Filipino': 10166502.0, 'Hindi': 13876974.0, 'Maya': 50859889.0, 'Kazakh': 77231.0, 'Telugu': 6498000.0, 'Cantonese': 32333860.0, 'Japanese': 15081783.0, 'Aramaic': 499263.0, 'Italian': 15091542.0, 'Dutch': 4398392.0, 'Dari': 15797907.0, 'German': 11433134.0, 'Hebrew': 2408553.0, 'Mongolian': 5701643.0, 'Russian': 1487477.0, 'Thai': 11905519.0, 'Polish': 3826455.0, 'Bosnian': 301305.0, 'Korean': 2181290.0, 'Hungarian': 195888.0, 'Portuguese': 7563397.0, nan: 3000000.0, 'Icelandic': 11835.0, 'Danish': 1647780.0, 'Chinese': 50000.0, 'Norwegian': 1196752.0, 'Czech': 617228.0, 'Swedish': 188870.0, 'None': 2601847.0, 'Zulu': 2912363.0, 'Dzongkha': 505295.0, 'Arabic': 1060591.0, 'Vietnamese': 638951.0, 'Indonesian': 4105123.0, 'Romanian': 1185783.0, 'Persian': 7098492.0, 'Greek': 110197.0} \n",
      "\n",
      "\n",
      "Original query 3 = [array(['USA', 3807], dtype=object), array(['UK', 448], dtype=object), array(['France', 154], dtype=object)] \n",
      "Randomized query 3 = [array([['Russia', 11]], dtype=object), array([['Japan', 23]], dtype=object), array([['Israel', 4]], dtype=object)] \n",
      "Sensitivity query 3 = 3807 \n",
      "\n",
      "\n",
      "[array([['Russia', 11]], dtype=object), array([['Japan', 23]], dtype=object), array([['Israel', 4]], dtype=object)]\n",
      "Budget 1 \n",
      "\n",
      "Original query 1 = 760505847.0 \n",
      "Randomized query 1 = Saving Private PerezÂ  \n",
      "Sensitivity query 1 = 760505847.0 \n",
      "\n",
      "\n",
      "Original query 2 = {'English': (760505847.0, 'Avatar\\xa0'), 'Mandarin': (128067808.0, 'Crouching Tiger, Hidden Dragon\\xa0'), 'Aboriginal': (72515360.0, 'The Interpreter\\xa0'), 'Spanish': (45356386.0, 'The Legend of Zorro\\xa0'), 'French': (77413017.0, 'March of the Penguins\\xa0'), 'Filipino': (10166502.0, 'The Great Raid\\xa0'), 'Hindi': (13876974.0, 'Monsoon Wedding\\xa0'), 'Maya': (50859889.0, 'Apocalypto\\xa0'), 'Kazakh': (77231.0, 'Nomad: The Warrior\\xa0'), 'Telugu': (6498000.0, 'Baahubali: The Beginning\\xa0'), 'Cantonese': (32333860.0, 'Rumble in the Bronx\\xa0'), 'Japanese': (15081783.0, 'Ponyo\\xa0'), 'Aramaic': (499263.0, 'The Passion of the Christ\\xa0'), 'Italian': (15091542.0, 'The Adventures of Pinocchio\\xa0'), 'Dutch': (4398392.0, 'Black Book\\xa0'), 'Dari': (15797907.0, 'The Kite Runner\\xa0'), 'German': (11433134.0, 'Das Boot\\xa0'), 'Hebrew': (2408553.0, 'The Gatekeepers\\xa0'), 'Mongolian': (5701643.0, 'Mongol: The Rise of Genghis Khan\\xa0'), 'Russian': (1487477.0, 'Night Watch\\xa0'), 'Thai': (11905519.0, 'The Protector\\xa0'), 'Polish': (3826455.0, 'Ida\\xa0'), 'Bosnian': (301305.0, 'In the Land of Blood and Honey\\xa0'), 'Korean': (2181290.0, 'Oldboy\\xa0'), 'Hungarian': (195888.0, 'Fateless\\xa0'), 'Portuguese': (7563397.0, 'City of God\\xa0'), nan: (3000000.0, 'Over the Hill to the Poorhouse\\xa0'), 'Icelandic': (11835.0, 'Of Horses and Men\\xa0'), 'Danish': (1647780.0, 'The Celebration\\xa0'), 'Chinese': (50000.0, 'My Lucky Star\\xa0'), 'Norwegian': (1196752.0, 'Headhunters\\xa0'), 'Czech': (617228.0, 'I Served the King of England\\xa0'), 'Swedish': (188870.0, 'Easy Money\\xa0'), 'None': (2601847.0, 'Samsara\\xa0'), 'Zulu': (2912363.0, 'Tsotsi\\xa0'), 'Dzongkha': (505295.0, 'Travelers and Magicians\\xa0'), 'Arabic': (1060591.0, 'Caramel\\xa0'), 'Vietnamese': (638951.0, 'Journey from the Fall\\xa0'), 'Indonesian': (4105123.0, 'The Raid: Redemption\\xa0'), 'Romanian': (1185783.0, '4 Months, 3 Weeks and 2 Days\\xa0'), 'Persian': (7098492.0, 'A Separation\\xa0'), 'Greek': (110197.0, 'Dogtooth\\xa0')} \n",
      "Randomized query 2 = {'English': array([[100241322.0, 'Shakespeare in Love\\xa0', 'English']], dtype=object), 'Mandarin': array([[626809.0, 'Red Cliff\\xa0', 'Mandarin']], dtype=object), 'Aboriginal': array([[72515360.0, 'The Interpreter\\xa0', 'Aboriginal']], dtype=object), 'Spanish': array([[1221261.0, 'Nine Queens\\xa0', 'Spanish']], dtype=object), 'French': array([[2874.0, 'The Girl on the Train\\xa0', 'French']], dtype=object), 'Filipino': array([[10166502.0, 'The Great Raid\\xa0', 'Filipino']], dtype=object), 'Hindi': array([[4018695.0, 'My Name Is Khan\\xa0', 'Hindi']], dtype=object), 'Maya': array([[50859889.0, 'Apocalypto\\xa0', 'Maya']], dtype=object), 'Kazakh': array([[77231.0, 'Nomad: The Warrior\\xa0', 'Kazakh']], dtype=object), 'Telugu': array([[6498000.0, 'Baahubali: The Beginning\\xa0', 'Telugu']],\n",
      "      dtype=object), 'Cantonese': array([[2126511.0, 'Ip Man 3\\xa0', 'Cantonese']], dtype=object), 'Japanese': array([[48856.0, 'Madadayo\\xa0', 'Japanese']], dtype=object), 'Aramaic': array([[499263.0, 'The Passion of the Christ\\xa0', 'Aramaic']],\n",
      "      dtype=object), 'Italian': array([[2835886.0, 'The Great Beauty\\xa0', 'Italian']], dtype=object), 'Dutch': array([[4398392.0, 'Black Book\\xa0', 'Dutch']], dtype=object), 'Dari': array([[15797907.0, 'The Kite Runner\\xa0', 'Dari']], dtype=object), 'German': array([[100412.0, 'Buen DÃ­a, RamÃ³n\\xa0', 'German']], dtype=object), 'Hebrew': array([[34151.0, 'Censored Voices\\xa0', 'Hebrew']], dtype=object), 'Mongolian': array([[5701643.0, 'Mongol: The Rise of Genghis Khan\\xa0', 'Mongolian']],\n",
      "      dtype=object), 'Russian': array([[1487477.0, 'Night Watch\\xa0', 'Russian']], dtype=object), 'Thai': array([[11905519.0, 'The Protector\\xa0', 'Thai']], dtype=object), 'Polish': array([[447093.0, 'Dekalog\\xa0            ', 'Polish']], dtype=object), 'Bosnian': array([[301305.0, 'In the Land of Blood and Honey\\xa0', 'Bosnian']],\n",
      "      dtype=object), 'Korean': array([[128486.0, 'The Good, the Bad, the Weird\\xa0', 'Korean']],\n",
      "      dtype=object), 'Hungarian': array([[195888.0, 'Fateless\\xa0', 'Hungarian']], dtype=object), 'Portuguese': array([[7563397.0, 'City of God\\xa0', 'Portuguese']], dtype=object), nan: array([[1066555.0, 'September Dawn\\xa0', nan]], dtype=object), 'Icelandic': array([[11835.0, 'Of Horses and Men\\xa0', 'Icelandic']], dtype=object), 'Danish': array([[1647780.0, 'The Celebration\\xa0', 'Danish']], dtype=object), 'Chinese': array([[50000.0, 'My Lucky Star\\xa0', 'Chinese']], dtype=object), 'Norwegian': array([[313436.0, 'Elling\\xa0', 'Norwegian']], dtype=object), 'Czech': array([[617228.0, 'I Served the King of England\\xa0', 'Czech']],\n",
      "      dtype=object), 'Swedish': array([[188870.0, 'Easy Money\\xa0', 'Swedish']], dtype=object), 'None': array([[2601847.0, 'Samsara\\xa0', 'None']], dtype=object), 'Zulu': array([[2912363.0, 'Tsotsi\\xa0', 'Zulu']], dtype=object), 'Dzongkha': array([[505295.0, 'Travelers and Magicians\\xa0', 'Dzongkha']],\n",
      "      dtype=object), 'Arabic': array([[1060591.0, 'Caramel\\xa0', 'Arabic']], dtype=object), 'Vietnamese': array([[638951.0, 'Journey from the Fall\\xa0', 'Vietnamese']],\n",
      "      dtype=object), 'Indonesian': array([[4105123.0, 'The Raid: Redemption\\xa0', 'Indonesian']],\n",
      "      dtype=object), 'Romanian': array([[1185783.0, '4 Months, 3 Weeks and 2 Days\\xa0', 'Romanian']],\n",
      "      dtype=object), 'Persian': array([[439958.0, 'Circumstance\\xa0', 'Persian']], dtype=object), 'Greek': array([[110197.0, 'Dogtooth\\xa0', 'Greek']], dtype=object)} \n",
      "Sensitivity query 2 = {'English': 760505847.0, 'Mandarin': 128067808.0, 'Aboriginal': 72515360.0, 'Spanish': 45356386.0, 'French': 77413017.0, 'Filipino': 10166502.0, 'Hindi': 13876974.0, 'Maya': 50859889.0, 'Kazakh': 77231.0, 'Telugu': 6498000.0, 'Cantonese': 32333860.0, 'Japanese': 15081783.0, 'Aramaic': 499263.0, 'Italian': 15091542.0, 'Dutch': 4398392.0, 'Dari': 15797907.0, 'German': 11433134.0, 'Hebrew': 2408553.0, 'Mongolian': 5701643.0, 'Russian': 1487477.0, 'Thai': 11905519.0, 'Polish': 3826455.0, 'Bosnian': 301305.0, 'Korean': 2181290.0, 'Hungarian': 195888.0, 'Portuguese': 7563397.0, nan: 3000000.0, 'Icelandic': 11835.0, 'Danish': 1647780.0, 'Chinese': 50000.0, 'Norwegian': 1196752.0, 'Czech': 617228.0, 'Swedish': 188870.0, 'None': 2601847.0, 'Zulu': 2912363.0, 'Dzongkha': 505295.0, 'Arabic': 1060591.0, 'Vietnamese': 638951.0, 'Indonesian': 4105123.0, 'Romanian': 1185783.0, 'Persian': 7098492.0, 'Greek': 110197.0} \n",
      "\n",
      "\n",
      "Original query 3 = [array(['USA', 3807], dtype=object), array(['UK', 448], dtype=object), array(['France', 154], dtype=object)] \n",
      "Randomized query 3 = [array([['Pakistan', 1]], dtype=object), array([['USA', 3807]], dtype=object), array([['Australia', 55]], dtype=object)] \n",
      "Sensitivity query 3 = 3807 \n",
      "\n",
      "\n",
      "[array([['Pakistan', 1]], dtype=object), array([['USA', 3807]], dtype=object), array([['Australia', 55]], dtype=object)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget 10 \n",
      "\n",
      "Original query 1 = 760505847.0 \n",
      "Randomized query 1 = Scary Movie 2Â  \n",
      "Sensitivity query 1 = 760505847.0 \n",
      "\n",
      "\n",
      "Original query 2 = {'English': (760505847.0, 'Avatar\\xa0'), 'Mandarin': (128067808.0, 'Crouching Tiger, Hidden Dragon\\xa0'), 'Aboriginal': (72515360.0, 'The Interpreter\\xa0'), 'Spanish': (45356386.0, 'The Legend of Zorro\\xa0'), 'French': (77413017.0, 'March of the Penguins\\xa0'), 'Filipino': (10166502.0, 'The Great Raid\\xa0'), 'Hindi': (13876974.0, 'Monsoon Wedding\\xa0'), 'Maya': (50859889.0, 'Apocalypto\\xa0'), 'Kazakh': (77231.0, 'Nomad: The Warrior\\xa0'), 'Telugu': (6498000.0, 'Baahubali: The Beginning\\xa0'), 'Cantonese': (32333860.0, 'Rumble in the Bronx\\xa0'), 'Japanese': (15081783.0, 'Ponyo\\xa0'), 'Aramaic': (499263.0, 'The Passion of the Christ\\xa0'), 'Italian': (15091542.0, 'The Adventures of Pinocchio\\xa0'), 'Dutch': (4398392.0, 'Black Book\\xa0'), 'Dari': (15797907.0, 'The Kite Runner\\xa0'), 'German': (11433134.0, 'Das Boot\\xa0'), 'Hebrew': (2408553.0, 'The Gatekeepers\\xa0'), 'Mongolian': (5701643.0, 'Mongol: The Rise of Genghis Khan\\xa0'), 'Russian': (1487477.0, 'Night Watch\\xa0'), 'Thai': (11905519.0, 'The Protector\\xa0'), 'Polish': (3826455.0, 'Ida\\xa0'), 'Bosnian': (301305.0, 'In the Land of Blood and Honey\\xa0'), 'Korean': (2181290.0, 'Oldboy\\xa0'), 'Hungarian': (195888.0, 'Fateless\\xa0'), 'Portuguese': (7563397.0, 'City of God\\xa0'), nan: (3000000.0, 'Over the Hill to the Poorhouse\\xa0'), 'Icelandic': (11835.0, 'Of Horses and Men\\xa0'), 'Danish': (1647780.0, 'The Celebration\\xa0'), 'Chinese': (50000.0, 'My Lucky Star\\xa0'), 'Norwegian': (1196752.0, 'Headhunters\\xa0'), 'Czech': (617228.0, 'I Served the King of England\\xa0'), 'Swedish': (188870.0, 'Easy Money\\xa0'), 'None': (2601847.0, 'Samsara\\xa0'), 'Zulu': (2912363.0, 'Tsotsi\\xa0'), 'Dzongkha': (505295.0, 'Travelers and Magicians\\xa0'), 'Arabic': (1060591.0, 'Caramel\\xa0'), 'Vietnamese': (638951.0, 'Journey from the Fall\\xa0'), 'Indonesian': (4105123.0, 'The Raid: Redemption\\xa0'), 'Romanian': (1185783.0, '4 Months, 3 Weeks and 2 Days\\xa0'), 'Persian': (7098492.0, 'A Separation\\xa0'), 'Greek': (110197.0, 'Dogtooth\\xa0')} \n",
      "Randomized query 2 = {'English': array([[52799004.0, 'Message in a Bottle\\xa0', 'English']], dtype=object), 'Mandarin': array([[128067808.0, 'Crouching Tiger, Hidden Dragon\\xa0', 'Mandarin']],\n",
      "      dtype=object), 'Aboriginal': array([[72515360.0, 'The Interpreter\\xa0', 'Aboriginal']], dtype=object), 'Spanish': array([[44456509.0, 'Instructions Not Included\\xa0', 'Spanish']],\n",
      "      dtype=object), 'French': array([[4857376.0, \"Paris, je t'aime\\xa0\", 'French']], dtype=object), 'Filipino': array([[10166502.0, 'The Great Raid\\xa0', 'Filipino']], dtype=object), 'Hindi': array([[13876974.0, 'Monsoon Wedding\\xa0', 'Hindi']], dtype=object), 'Maya': array([[50859889.0, 'Apocalypto\\xa0', 'Maya']], dtype=object), 'Kazakh': array([[77231.0, 'Nomad: The Warrior\\xa0', 'Kazakh']], dtype=object), 'Telugu': array([[6498000.0, 'Baahubali: The Beginning\\xa0', 'Telugu']],\n",
      "      dtype=object), 'Cantonese': array([[32333860.0, 'Rumble in the Bronx\\xa0', 'Cantonese']], dtype=object), 'Japanese': array([[10037390.0, 'Godzilla 2000\\xa0', 'Japanese']], dtype=object), 'Aramaic': array([[499263.0, 'The Passion of the Christ\\xa0', 'Aramaic']],\n",
      "      dtype=object), 'Italian': array([[6100000.0, 'The Good, the Bad and the Ugly\\xa0', 'Italian']],\n",
      "      dtype=object), 'Dutch': array([[4398392.0, 'Black Book\\xa0', 'Dutch']], dtype=object), 'Dari': array([[15797907.0, 'The Kite Runner\\xa0', 'Dari']], dtype=object), 'German': array([[11433134.0, 'Das Boot\\xa0', 'German']], dtype=object), 'Hebrew': array([[2283276.0, 'Waltz with Bashir\\xa0', 'Hebrew']], dtype=object), 'Mongolian': array([[5701643.0, 'Mongol: The Rise of Genghis Khan\\xa0', 'Mongolian']],\n",
      "      dtype=object), 'Russian': array([[1487477.0, 'Night Watch\\xa0', 'Russian']], dtype=object), 'Thai': array([[11905519.0, 'The Protector\\xa0', 'Thai']], dtype=object), 'Polish': array([[3826455.0, 'Ida\\xa0', 'Polish']], dtype=object), 'Bosnian': array([[301305.0, 'In the Land of Blood and Honey\\xa0', 'Bosnian']],\n",
      "      dtype=object), 'Korean': array([[2181290.0, 'Oldboy\\xa0', 'Korean']], dtype=object), 'Hungarian': array([[195888.0, 'Fateless\\xa0', 'Hungarian']], dtype=object), 'Portuguese': array([[7563397.0, 'City of God\\xa0', 'Portuguese']], dtype=object), nan: array([[3000000.0, 'Over the Hill to the Poorhouse\\xa0', nan]],\n",
      "      dtype=object), 'Icelandic': array([[11835.0, 'Of Horses and Men\\xa0', 'Icelandic']], dtype=object), 'Danish': array([[1647780.0, 'The Celebration\\xa0', 'Danish']], dtype=object), 'Chinese': array([[50000.0, 'My Lucky Star\\xa0', 'Chinese']], dtype=object), 'Norwegian': array([[1196752.0, 'Headhunters\\xa0', 'Norwegian']], dtype=object), 'Czech': array([[617228.0, 'I Served the King of England\\xa0', 'Czech']],\n",
      "      dtype=object), 'Swedish': array([[188870.0, 'Easy Money\\xa0', 'Swedish']], dtype=object), 'None': array([[2601847.0, 'Samsara\\xa0', 'None']], dtype=object), 'Zulu': array([[2912363.0, 'Tsotsi\\xa0', 'Zulu']], dtype=object), 'Dzongkha': array([[505295.0, 'Travelers and Magicians\\xa0', 'Dzongkha']],\n",
      "      dtype=object), 'Arabic': array([[1060591.0, 'Caramel\\xa0', 'Arabic']], dtype=object), 'Vietnamese': array([[638951.0, 'Journey from the Fall\\xa0', 'Vietnamese']],\n",
      "      dtype=object), 'Indonesian': array([[4105123.0, 'The Raid: Redemption\\xa0', 'Indonesian']],\n",
      "      dtype=object), 'Romanian': array([[1185783.0, '4 Months, 3 Weeks and 2 Days\\xa0', 'Romanian']],\n",
      "      dtype=object), 'Persian': array([[7098492.0, 'A Separation\\xa0', 'Persian']], dtype=object), 'Greek': array([[110197.0, 'Dogtooth\\xa0', 'Greek']], dtype=object)} \n",
      "Sensitivity query 2 = {'English': 760505847.0, 'Mandarin': 128067808.0, 'Aboriginal': 72515360.0, 'Spanish': 45356386.0, 'French': 77413017.0, 'Filipino': 10166502.0, 'Hindi': 13876974.0, 'Maya': 50859889.0, 'Kazakh': 77231.0, 'Telugu': 6498000.0, 'Cantonese': 32333860.0, 'Japanese': 15081783.0, 'Aramaic': 499263.0, 'Italian': 15091542.0, 'Dutch': 4398392.0, 'Dari': 15797907.0, 'German': 11433134.0, 'Hebrew': 2408553.0, 'Mongolian': 5701643.0, 'Russian': 1487477.0, 'Thai': 11905519.0, 'Polish': 3826455.0, 'Bosnian': 301305.0, 'Korean': 2181290.0, 'Hungarian': 195888.0, 'Portuguese': 7563397.0, nan: 3000000.0, 'Icelandic': 11835.0, 'Danish': 1647780.0, 'Chinese': 50000.0, 'Norwegian': 1196752.0, 'Czech': 617228.0, 'Swedish': 188870.0, 'None': 2601847.0, 'Zulu': 2912363.0, 'Dzongkha': 505295.0, 'Arabic': 1060591.0, 'Vietnamese': 638951.0, 'Indonesian': 4105123.0, 'Romanian': 1185783.0, 'Persian': 7098492.0, 'Greek': 110197.0} \n",
      "\n",
      "\n",
      "Original query 3 = [array(['USA', 3807], dtype=object), array(['UK', 448], dtype=object), array(['France', 154], dtype=object)] \n",
      "Randomized query 3 = [array([['Slovenia', 1]], dtype=object), array([['Finland', 1]], dtype=object), array([['South Africa', 8]], dtype=object)] \n",
      "Sensitivity query 3 = 3807 \n",
      "\n",
      "\n",
      "[array([['Slovenia', 1]], dtype=object), array([['Finland', 1]], dtype=object), array([['South Africa', 8]], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "main('movie_metadata.csv', [0.1, 1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
