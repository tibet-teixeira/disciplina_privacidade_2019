{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import expon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "COLUMN NAME - INDEX\n",
    "gross           8\n",
    "movie_title    11\n",
    "language       19\n",
    "country        20\n",
    "'''\n",
    "def loadDataset(filename):\n",
    "    dataset = pd.read_csv(filename, delimiter=',')\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Color', 'James Cameron', 723.0, ..., 7.9, 1.78, 33000],\n",
       "       ['Color', 'Gore Verbinski', 302.0, ..., 7.1, 2.35, 0],\n",
       "       ['Color', 'Sam Mendes', 602.0, ..., 6.8, 2.35, 85000],\n",
       "       ...,\n",
       "       ['Color', 'Benjamin Roberds', 13.0, ..., 6.3, nan, 16],\n",
       "       ['Color', 'Daniel Hsia', 14.0, ..., 6.3, 2.35, 660],\n",
       "       ['Color', 'Jon Gunn', 43.0, ..., 6.6, 1.85, 456]], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG\n",
    "datasetTest = loadDataset('movie_metadata.csv')\n",
    "datasetTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove line limite  \n",
    "def clearingDatasetQuery1(dataset):\n",
    "    subset = dataset[0:100, [8, 11]]\n",
    "    new_dataset = list()\n",
    "    for record in subset:\n",
    "        if not(math.isnan(record[0])):\n",
    "            new_dataset.append(record)\n",
    "    return np.array(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove line limite  \n",
    "def clearingDatasetQuery2(dataset):   \n",
    "    subset = dataset[300:400, [8, 11, 19]]\n",
    "    new_dataset = list()\n",
    "    for record in subset:\n",
    "        if not(math.isnan(record[0])):\n",
    "            new_dataset.append(record)\n",
    "    return np.array(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possibleValues(dataset, query):  \n",
    "    if query == 1:\n",
    "        cleanDataset = clearingDatasetQuery1(dataset)\n",
    "    elif query == 2:\n",
    "        cleanDataset = clearingDatasetQuery2(dataset)\n",
    "    elif query == 3:\n",
    "        cleanDataset = clearingDatasetQuery3(dataset)\n",
    "    else:\n",
    "        print('Consulta inválida')\n",
    "        return None\n",
    "       \n",
    "    indexRecord = 0\n",
    "    titleUniqueMovies = list()\n",
    "    removingReplicates = np.copy(cleanDataset)\n",
    "    \n",
    "    for record in cleanDataset:\n",
    "        if record[1] not in titleUniqueMovies:\n",
    "            titleUniqueMovies.append(record[1])\n",
    "        else:\n",
    "            removingReplicates = np.delete(removingReplicates, indexRecord, 0)\n",
    "            indexRecord -= 1\n",
    "            \n",
    "        indexRecord += 1\n",
    "       \n",
    "    return np.array(removingReplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "datasetQuery1 = possibleValues(datasetTest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "datasetQuery2 = possibleValues(datasetTest, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query1(dataset):\n",
    "    maxGross = np.max(dataset[:, 0], axis=0)\n",
    "    return dataset[np.where(dataset[:,0] == maxGross)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query2(dataset):\n",
    "    movieDict = dict()\n",
    "    maxGrossPerLanguage = dict()\n",
    "    \n",
    "    for record in dataset:\n",
    "        if record[2] in movieDict.keys():\n",
    "            movieDict[record[2]].append(record)\n",
    "        else:\n",
    "            movieDict[record[2]] = []\n",
    "            movieDict[record[2]].append(record)\n",
    "        \n",
    "    for key in movieDict.keys():\n",
    "        maxGross = float('-inf')\n",
    "        movieName = None\n",
    "        for value in movieDict[key]:\n",
    "            if value[0] > maxGross:\n",
    "                maxGross = value[0]\n",
    "                movieName = value[1]\n",
    "\n",
    "        maxGrossPerLanguage[key] = (maxGross, movieName)\n",
    "\n",
    "    return maxGrossPerLanguage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([760505847.0, 'Avatar\\xa0'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG\n",
    "query1(datasetQuery1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'English': (380838870.0, 'Finding Nemo\\xa0'),\n",
       " 'Mandarin': (9213.0, 'The Flowers of War\\xa0'),\n",
       " 'Aboriginal': (72515360.0, 'The Interpreter\\xa0')}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG\n",
    "query2(datasetQuery2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreFunctionQuery1(dataset, output):\n",
    "    score = list()\n",
    "       \n",
    "    for record in dataset:       \n",
    "        if record[1] == output:\n",
    "            score.append(record[0])\n",
    "        else:\n",
    "            score.append(0)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreFunctionQuery2(dataset, language, output):\n",
    "    score = list()\n",
    "       \n",
    "    for record in dataset:       \n",
    "        if record[1] == output:\n",
    "            score.append(record[0])\n",
    "        else:\n",
    "            score.append(0)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivityQuery1(dataset):\n",
    "    datasetWithoutCurrentOutput = dataset[:,:]\n",
    "    \n",
    "    maxScore = float('-inf')\n",
    "    indexOutput = 0\n",
    "    \n",
    "    for output in dataset:\n",
    "        lenDataset = len(datasetWithoutCurrentOutput)\n",
    "        datasetWithoutCurrentOutput = datasetWithoutCurrentOutput[np.delete(np.array(range(lenDataset)), 0),:]\n",
    "        neighborDataset = datasetWithoutCurrentOutput[:,:]\n",
    "        \n",
    "        scoreQ1 = scoreFunctionQuery1(dataset, output[1])\n",
    "        maxScoreQ1 = np.max(scoreQ1)\n",
    "        minScoreQ1 = float('inf')\n",
    "    \n",
    "        for index in range(lenDataset - 1):\n",
    "            lenNeighborDataset = len(neighborDataset)\n",
    "            neighborDataset = neighborDataset[np.delete(np.array(range(lenNeighborDataset)), 0),:]\n",
    "            \n",
    "            for newOutput in neighborDataset:\n",
    "                newScoreQ1 = scoreFunctionQuery1(neighborDataset, newOutput[1])\n",
    "                minScoreNeighbor = np.min(newScoreQ1)\n",
    "\n",
    "            if minScoreQ1 > minScoreNeighbor:\n",
    "                minScoreQ1 = minScoreNeighbor \n",
    "                ScoreDifference = abs(maxScoreQ1 - minScoreQ1)\n",
    "\n",
    "                if maxScore < ScoreDifference:\n",
    "                    maxScore = ScoreDifference\n",
    "        \n",
    "        indexOutput += 1\n",
    "    \n",
    "    return maxScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Esta função deve calcular a sensibilidade de cada saída para o dataset de seu idioma.\n",
    "# Saídas de idiomas diferentes não fazem parte do dataset, portanto, é necessário dividir o dataset\n",
    "# por idioma e a partir disso calcular a sensibilidade\n",
    "\n",
    "def sensitivityQuery2(dataset):\n",
    "    datasetWithoutCurrentOutput = dataset[:,:]\n",
    "    \n",
    "    maxScore = float('-inf')\n",
    "    indexOutput = 0\n",
    "    \n",
    "    for output in dataset:\n",
    "        lenDataset = len(datasetWithoutCurrentOutput)\n",
    "        datasetWithoutCurrentOutput = datasetWithoutCurrentOutput[np.delete(np.array(range(lenDataset)), 0),:]\n",
    "        neighborDataset = datasetWithoutCurrentOutput[:,:]\n",
    "        \n",
    "        scoreQ1 = scoreFunctionQuery1(dataset, output[1])\n",
    "        maxScoreQ1 = np.max(scoreQ1)\n",
    "        minScoreQ1 = float('inf')\n",
    "    \n",
    "        for index in range(lenDataset - 1):\n",
    "            lenNeighborDataset = len(neighborDataset)\n",
    "            neighborDataset = neighborDataset[np.delete(np.array(range(lenNeighborDataset)), 0),:]\n",
    "            \n",
    "            for newOutput in neighborDataset:\n",
    "                newScoreQ1 = scoreFunctionQuery1(neighborDataset, newOutput[1])\n",
    "                minScoreNeighbor = np.min(newScoreQ1)\n",
    "\n",
    "            if minScoreQ1 > minScoreNeighbor:\n",
    "                minScoreQ1 = minScoreNeighbor \n",
    "                ScoreDifference = abs(maxScoreQ1 - minScoreQ1)\n",
    "\n",
    "                if maxScore < ScoreDifference:\n",
    "                    maxScore = ScoreDifference\n",
    "        \n",
    "        indexOutput += 1\n",
    "    \n",
    "    return maxScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760505847.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG\n",
    "sensQ1 = sensitivityQuery1(datasetQuery1)\n",
    "sensQ1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputRandomized(budget, sensitivity):\n",
    "    exp = expon.rvs(loc = 0, scale = sensitivity/budget)\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomizedQuery1(dataset, budget, sensitivity):\n",
    "    grosses = dataset[:, 0]\n",
    "    values = list()\n",
    "    for gross in grosses:\n",
    "        value = abs(gross - outputRandomized(budget, sensitivity))\n",
    "        values.append(value)\n",
    "\n",
    "    return dataset[np.argmin(values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([150167630.0, 'G.I. Joe: The Rise of Cobra\\xa0'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG\n",
    "randomizedQuery1(datasetQuery1, 0.1, sensQ1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(filename, budget):\n",
    "    dataset = loadDataset(filename)\n",
    "#     cleanDataset = possibleValues(datasetTest)\n",
    "    \n",
    "#     sensitivityQ1 = sensitivityQuery1(cleanDataset)\n",
    "#     result = randomizedQuery1(cleanDataset, budget, sensitivityQ1)\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmin of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2fafacdf449a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'movie_metadata.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-e017c8ee7e15>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(filename, budget)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msensitivityQ1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msensitivityQuery1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleanDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandomizedQuery1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleanDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msensitivityQ1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-ad46c82b4125>\u001b[0m in \u001b[0;36mrandomizedQuery1\u001b[1;34m(dataset, budget, sensitivity)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmin\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmin\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m-> 1222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
     ]
    }
   ],
   "source": [
    "main('movie_metadata.csv', [])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
